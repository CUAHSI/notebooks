{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db250eac-dd32-4895-88bb-72ccbb8f5ca2",
   "metadata": {},
   "source": [
    "# Retrieving and Aggregating AORC Data at a Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1958827-496d-44a2-9b2d-ba557c8fb0fa",
   "metadata": {},
   "source": [
    "**Authors:** \n",
    "\n",
    "<ul style=\"line-height:1.5;\">\n",
    "<li>Ayman Nassar <a href=\"mailto:ayman.nassar@usu.edu\">(ayman.nassar@usu.edu)</a></li>\n",
    "<li>David Tarboton <a href=\"mailto:david.tarboton@usu.edu\">(david.tarboton@usu.edu)</a></li>\n",
    "<li>Homa Salehabadi <a href=\"mailto:homa.salehabadi@usu.edu\">(homa.salehabadi@usu.edu)</a></li>\n",
    "<li>Anthony Castronova <a href=\"mailto:acastronova@cuahsi.org\">(acastronova@cuahsi.org)</a></li>\n",
    "<li>Pabitra Dash <a href=\"mailto:pabitra.dash@usu.edu\">(pabitra.dash@usu.edu)</a></li>\n",
    "</ul>\n",
    "\n",
    "**Last Updated:** 2/21/2025\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "This notebook provides code examples for retrieving NOAA Analysis of Record for Calibration (AORC) data from Amazon Web Services (AWS). It is intended to make it easy for researchers to access data for a specific point specified by latitude and longitude or known geographic coordinates. It also allows for data aggregation at time scales different from the underlying NOAA data.\n",
    "\n",
    "**Audience:**\n",
    "\n",
    "Researchers who are familiar with Jupyter Notebooks, basic Python and basic hydrologic data analysis.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This notebook takes as inputs the coordinates (e.g. latitude and longitude) of a study location in any coordinate system, start and end dates for the desired study period, a variable name, and a preferred time aggregation interval. It then retrieves data from Amazon Web Services (AWS), aggregates it over the specified time interval, displays the data as a plot, and saves it as a comma separated variable (CSV) file.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "This notebook uses AORC data developed and published by NOAA on Amazon Web Services (AWS) as described in detail in this registry of open data entry <https://registry.opendata.aws/noaa-nws-aorc/>. The AORC dataset is a gridded record of near-surface weather conditions covering the continental United States and Alaska and their hydrologically contributing areas. It is defined on a latitude/longitude spatial grid with a mesh length of 30 arc seconds (~800 m), and a temporal resolution of one hour. This notebook uses the Zarr format files of version 1.1 of the AORC data. Zarr is a format for storage of chunked, compressed, N-dimensional arrays, designed to support storage using distributed systems such as cloud object stores (<https://zarr.dev/>).\n",
    "\n",
    "\n",
    "**Software Requirements:**\n",
    "\n",
    "This notebook has been tested using Python v3.11.8 using the following library versions:\n",
    "\n",
    " >  numpy: 1.26.4  \n",
    "    geopandas: 0.14.4  \n",
    "    matplotlib: 3.8.3  \n",
    "    xarray: 2024.3.0  \n",
    "    s3fs: 2024.3.1  \n",
    "    fsspec: 2024.3.1  \n",
    "    contextily: 1.6.2  \n",
    "    zarr: 2.17.2  \n",
    "\n",
    "It also uses code from aorc_utils.py that accompanies this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd810b-9a55-4da7-8ce8-2089c8209abf",
   "metadata": {},
   "source": [
    "Use the following command to ensure that all dependencies are installed in your environment. Note, these library versions have been pinned and tested for `Python 3.11.8`. Install and import the libraries needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83a7ff-0e3d-4d8f-be62-66b2a12c9bac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note: this cell can be skipped if the dependencies have already been installed.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d61a5-bf09-4b2d-930f-b1bf944fa411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import contextily as ctx \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from aorc_utils import (get_conus_bucket_url, load_dataset,\n",
    "                        reproject_coordinates, get_variable_code,\n",
    "                        get_aggregation_code, get_time_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63434088-5ea0-4eef-a2f0-3521b0e49cad",
   "metadata": {},
   "source": [
    "### 2. Set Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0857572-0a64-496a-8d57-b585ecc5417d",
   "metadata": {},
   "source": [
    "Set values that specify which data to retrieve. The coordinate system for the point latitude (`y`) and longitude (`x`) coordinates must be specified using European Petroleum Survey Group (EPSG) code.  EPSG codes are a widely used coordinate system encoding and can be found at [https://spatialreference.org/](https://spatialreference.org/). The specific EPSG value of 4326 given in the cell below references the World Geodetic System of 1984 (WGS84) geographic latitude and longitude coordinate system. Thus the input `lon` and `lat` values are interpreted as being in this coordinate system. If your data is in a different coordinate system, you need to look up its EPSG code at the website above and use it in the cell below.  To learn more about coordinate systems, see, for example, the [UCGIS body of Knowledge section on Coordinate Systems](https://gistbok-topics.ucgis.org/DM-05-047).\n",
    "\n",
    "\n",
    "Additionally, the following variables can be retrieved from the AORC dataset.\n",
    "\n",
    "|Common Name|Variable Name|Description|\n",
    "|---|---|---|\n",
    "|Total Precipitation| APCP_surface | Hourly total precipitation (kgm-2 or mm) |\n",
    "|Air Temperature| TMP_2maboveground | Temperature (at 2 m above-ground-level (AGL)) (K) |\n",
    "|Specific Humidity| SPFH_2maboveground | Specific humidity (at 2 m AGL) (g g-1) |\n",
    "|Downward Long-Wave Radiation Flux| DLWRF_surface | longwave (infrared) radiation flux (at the surface) (W m-2) |\n",
    "|Downward Short-Wave Radiation Flux| DSWRF_surface | Downward shortwave (solar) radiation flux (at the surface) (W m-2) |\n",
    "|Pressure| PRES_surface | Air pressure (at the surface) (Pa) |\n",
    "|U-Component of Wind| UGRD_10maboveground) | (west to east) - components of the wind (at 10 m AGL) (m s-1) |\n",
    "|V-Component of Wind| VGRD_10maboveground) | (south to north) - components of the wind (at 10 m AGL) (m s-1)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc77e5-70cd-483e-807e-dfbab644c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start date - In Year-Month-Day format, the earliest start date can be '1979-02-01'\n",
    "start_datetime = '1990-01-01'\n",
    "\n",
    "# End date - In Year-Month-Day format, the latest end date can be '2023-01-31'\n",
    "end_datetime = '1990-12-31'\n",
    "\n",
    "# Coordinate system EPSG code (from https://spatialreference.org/).\n",
    "input_crs = 'EPSG:4326'\n",
    "\n",
    "# Point location\n",
    "# lon, lat are used as names, even for projected coordinate systems where lon = x and lat = y\n",
    "lon = -111.96503  \n",
    "lat = 40.77069  \n",
    "\n",
    "# User-defined variable - see above for a list of valid variable names\n",
    "variable_name = 'Total Precipitation'\n",
    "\n",
    "# User-defined aggregation interval - valid values are 'hour','day','month','year'  \n",
    "agg_interval = 'day'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0a269-ce5f-4485-a316-f04f34f10b2d",
   "metadata": {},
   "source": [
    "### 3. Display Map with Point Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6fa17-10b0-48bb-a367-31b092a6cbf8",
   "metadata": {},
   "source": [
    "Render a simple map to show the location of the point entered. This is done by first plotting the `lat`,`lon` point defined above using the `GeoPandas` library, and then adding a basemap using the `Contextily` library. This is not needed for extraction of the data at the input location but serves as a check on the input location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c0559-3c85-4319-a676-4c8b8f15a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point location\n",
    "point = Point(lon, lat)\n",
    "\n",
    "# Create a GeoDataFrame with the point\n",
    "gdf_point = gpd.GeoDataFrame(geometry=[point], crs=input_crs)\n",
    "\n",
    "# Create a layout for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Display the point location\n",
    "gdf_point.plot(ax=ax, color='red', marker='o', markersize=100, label='Point Location')\n",
    "\n",
    "# Add a topographic basemap using contextily \n",
    "ctx.add_basemap(ax,\n",
    "                source=ctx.providers.Esri.NatGeoWorldMap,\n",
    "                crs=gdf_point.crs.to_string(),\n",
    "                alpha=1)\n",
    "\n",
    "# Customize x and y axis labels\n",
    "ax.set_title(\"Map with Point Location\", fontsize=14)\n",
    "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
    "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0e39e-c837-4fa5-9a36-9aa48f353ede",
   "metadata": {},
   "source": [
    "### 4. Virtually Load the Data Array \n",
    "\n",
    "The AORC dataset is very large, and impractical to download in its entirety. The `Xarray` library is used to reference and \"lazily\" retrieve only the parts that are needed. This works by reading a minimal set of metadata that will enable us to define analysis operations. The AORC dataset that we'll be loading is in the Zarr format and is hosted on Amazon S3: `s3://noaa-nwm-retrospective-3-0-pds/CONUS/zarr/`. The following code will load these data into an `Xarray` DataSet which we can then use to subset and aggregate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb25478-6445-43db-ab0f-6d98b42d7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable code\n",
    "variable_code = get_variable_code(variable_name)\n",
    "\n",
    "# Get the S3 bucket data file URL\n",
    "url = get_conus_bucket_url(variable_code)\n",
    "ds = load_dataset(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866aac5d-f720-44d1-bb2e-a2d427f51056",
   "metadata": {},
   "source": [
    "Print information on the dataset to show its AORC name, units and geographic coordinate system information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41ccd3-7f60-4ed1-9971-d855cc6431cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the selected variable and its units\n",
    "print(f\"Data Variable: {list(ds.data_vars)[0]}\")\n",
    "print(f\"{list(ds.data_vars)[0]} units: {ds[list(ds.data_vars)[0]].attrs.get('units', 'No units specified')}\\n\")\n",
    "\n",
    "# Print selected variable dataset information\n",
    "print(ds)\n",
    "\n",
    "print('\\n')\n",
    "print(f'Additional items associated with the {list(ds.data_vars)[0]} variable')\n",
    "for k, v in ds[list(ds.data_vars)[0]].attrs.items():\n",
    "    print(f'\\n{k} -> {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa2538-56d9-47c5-b851-c60a64a4ca09",
   "metadata": {},
   "source": [
    "### 5. Subset and Aggregate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6daf156-d821-4a10-b0df-e3c103025438",
   "metadata": {},
   "source": [
    "To work with a portion of the data, we isolate the section of it that we're interested in. This is done by performing a spatial subsetting operation using the `lat` and `lon` variables defined earlier. First, we convert our `lat` and `lon` values into the coordinate system used by the AORC data which is the Lambert Conformal Conic projection used by the National Water Model. This can be found in the attributes of the `DataSet` shown above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec25fd-d427-4dbe-980b-07e5572794ec",
   "metadata": {},
   "source": [
    "We retrieve data for an AORC grid cell with center nearest to the point of interest. The data associated with this cell can then be aggregated in time. The results are saved in a data frame `df_subset` which holds as columns time (date), x and y coordinates of the AORC grid cell center nearest to the input point (in the Lambert Conformal Conic coordinate system used by AORC) and the variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd8d12-71ac-41a9-a4ec-b8b1f0e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject coordinates\n",
    "x, y = reproject_coordinates(ds, lon, lat, input_crs)\n",
    "\n",
    "# Get aggregation code\n",
    "agg_code = get_aggregation_code(agg_interval)\n",
    "\n",
    "# Subsetting and aggregating the user-defined variable\n",
    "variable_code_cap = variable_code.upper()\n",
    "\n",
    "if variable_code == 'precip':\n",
    "    ds_subset = (\n",
    "        ds['RAINRATE']\n",
    "          .loc[dict(time=slice(start_datetime, end_datetime))]              # slice the data temporally \n",
    "          .sel(y=y, x=x, method='nearest')                                  # select the cell nearest an x and y\n",
    "          .compute() * 3600                                                 # retrieve the data and then perform unit conv                                   \n",
    "    )\n",
    "    df_subset = ds_subset.resample(time=agg_code).sum().to_dataframe()      # compute total rainfall per day\n",
    "    unit = f\"mm/{agg_interval}\"\n",
    "else:\n",
    "    ds_subset = (\n",
    "        ds[variable_code_cap]\n",
    "          .loc[dict(time=slice(start_datetime, end_datetime))]              # slice the data temporally \n",
    "          .sel(y=y, x=x, method='nearest').compute()                        # select the cell nearest an x and y, retrieve the data\n",
    "    )\n",
    "    ds_subset_df = ds_subset.resample(time=agg_code).mean().to_dataframe()  # compute mean\n",
    "    unit = ds[variable_code_cap].attrs.get('units', 'No units specified')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d463b4f0-3921-400c-98ea-7be1f454c0d6",
   "metadata": {},
   "source": [
    "Rename the column corresponding with the variable we aggregated above to include units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49788c-5174-4871-ab7c-c10db791a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the last column to include the unit\n",
    "df_subset.rename(columns={df_subset.columns[-1]: f\"{df_subset.columns[-1]} ({unit})\"}, inplace=True)\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802d1f5-cd5d-4f27-b5bd-d5068dc633a2",
   "metadata": {},
   "source": [
    "### 6. Plot the Data and Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a259d55-e871-46ac-8a25-70980f15603e",
   "metadata": {},
   "source": [
    "Plot the variable that was computed above with `time` on the x-axis and add a trend line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f695a1-e94f-40a3-ac56-769e2da43843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the time index and column to plot\n",
    "time_list=pd.to_datetime(df_subset.index)\n",
    "data_list = df_subset.iloc[:, 2]\n",
    "\n",
    "# Setup the plot\n",
    "plt.figure(figsize=(14, 8))  # Adjusting the size to provide more space for x-labels\n",
    "plt.plot(time_list, data_list, color='blue', linewidth=2, marker='o', markersize=6, markerfacecolor='red', markeredgewidth=1)\n",
    "plt.title(f'{variable_name} ({start_datetime[:]} - {end_datetime[:]})', fontsize=16)\n",
    "plt.xlabel(f'Date/time', fontsize=14)\n",
    "plt.ylabel(f'{variable_name} ({unit})', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Handling overlapping x-labels\n",
    "plt.xticks(rotation=45, ha='right')                           # Rotate labels and align them to the right\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(nbins=10))  # Show fewer labels to avoid overlap\n",
    "plt.gcf().autofmt_xdate()                                     # Automatically adjust x-label formatting for better spacing\n",
    "\n",
    "# Adding a trend line\n",
    "z = np.polyfit(range(len(time_list)), data_list, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(time_list, p(range(len(time_list))), color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving the plot\n",
    "plt.savefig(f'{agg_interval}_{variable_code}_plot_for_point.png', dpi=800)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3c688-f6b8-4a01-8486-95430322102e",
   "metadata": {},
   "source": [
    "### 7. Save the Data as a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cc1fc-ffb8-4599-887c-03809536959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "file_path = f\"{variable_name}_at_a_point.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_subset.to_csv(file_path, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-2024-03",
   "language": "python",
   "name": "python3-2024-03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
